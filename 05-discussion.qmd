---
title: "Discussion"
---

## Tracking urban growth using EO. Discussion

### Counting pixels

Once you have your individual land cover masks, you can count pixels and plot the time series. The following script can do that for you and plot a couple of interesting masks:

```javascript
/**** Assets ****/
var classifier = ee.Classifier.load('users/xgomezdans/BamakoRFClassifier');

var training = ee.FeatureCollection('users/xgomezdans/BamakoTraining2018');
var roi = training.geometry().bounds();

var bands = ["blue", "green", "red", "nir",
             "swir1", "swir2",
             "NDVI", "MNDWI", "NDBI", "UI", "IBI", "BRIGHT"];

var palette = [
  '#4575b4', // 0 water
  '#1a9850', // 1 veg
  '#d73027', // 2 bare
  '#fee08b'  // 3 builtup
];

/**** Client-side list of mosaics (IMPORTANT) ****/
var mosaics = [
  {year: 2000, path: 'users/xgomezdans/Bamako_Mosaic_2000'},
  {year: 2005, path: 'users/xgomezdans/Bamako_Mosaic_2005'},
  {year: 2010, path: 'users/xgomezdans/Bamako_Mosaic_2010'},
  {year: 2015, path: 'users/xgomezdans/Bamako_Mosaic_2015'},
  {year: 2018, path: 'users/xgomezdans/Bamako_Mosaic_2018'},
  {year: 2020, path: 'users/xgomezdans/Bamako_Mosaic_2020'},
  {year: 2024, path: 'users/xgomezdans/Bamako_Mosaic_2024'}
  // {year: 2025, path: 'users/xgomezdans/Bamako_Mosaic_2025'}
];

/**** Per-year pixel counts (server-side computations, but constant asset IDs) ****/
function countsFeature(year, path) {
  var img = ee.Image(path).select(bands);
  var cls = img.classify(classifier).rename('class');

  var scale = img.projection().nominalScale();

  var hist = ee.Dictionary(
    cls.reduceRegion({
      reducer: ee.Reducer.frequencyHistogram(),
      geometry: roi,
      scale: scale,
      bestEffort: true,
      maxPixels: 1e13
    }).get('class')
  );

  return ee.Feature(null, {
    year: year,
    class0: ee.Number(hist.get('0', 0)),
    class1: ee.Number(hist.get('1', 0)),
    class2: ee.Number(hist.get('2', 0)),
    class3: ee.Number(hist.get('3', 0))
  });
}

/**** Build FeatureCollection ****/
var feats = mosaics.map(function(m) {
  return countsFeature(m.year, m.path);
});
var fc = ee.FeatureCollection(feats).sort('year');
print('Pixel counts per class & year', fc);

/**** Plot evolution ****/
var chart = ui.Chart.feature.byFeature(fc, 'year', ['class0', 'class1', 'class2', 'class3'])
  .setChartType('LineChart')
  .setOptions({
    title: 'Bamako class pixel counts over time',
    hAxis: {title: 'Year', format: '####'},
    vAxis: {title: 'Pixel count'},
    lineWidth: 2,
    pointSize: 5,
    series: {
      0: {color: palette[0], labelInLegend: '0 water'},
      1: {color: palette[1], labelInLegend: '1 veg'},
      2: {color: palette[2], labelInLegend: '2 bare'},
      3: {color: palette[3], labelInLegend: '3 builtup'}
    }
  });
print(chart);

/**** Optional: map preview for first & last mosaic ****/
var first = mosaics[0];
var firstCls = ee.Image(first.path).select(bands).classify(classifier).clip(roi);


var last = mosaics[mosaics.length - 1];
var latestCls = ee.Image(last.path).select(bands).classify(classifier).clip(roi);

Map.centerObject(roi, 10);
Map.addLayer(roi, {}, 'ROI', false);
Map.addLayer(firstCls, {min: 0, max: 3, palette: palette}, 'Classified ' + first.year);
Map.addLayer(latestCls, {min: 0, max: 3, palette: palette}, 'Classified ' + last.year);
```


### The Bamako case

. In @fig-bamako-evolution, I show the evolution of Bamako in Mali. The curve shows a fairly constant growth between 1975 and 2020, growing from around 60 square km to more than 140 square km, but the growth appears to flatten after 2020. Note that this could be an effect of the relatively small area we're investigating (~20 km) becoming saturated and growth taking place elsewhere outside of our study area.

 We can also look at the spatial distribution of the growth (see @fig-bamako-map). Clearly, Bamako has continue growing along the Niger River, but also outside from it, and we can see how the build up area ends up making a continuum between the main Bamako city and the towns that existed around it in 2000. 


::: callout-note
If you are interested in the particular case of Bamako, you can read [(Keita et al. (2021))](https://doi.org/10.3390/urbansci5010004). This paper does something similar to what you have done here.

:::

![Evolution of the size of build up area for a radial region centred in Bamako (Mali) and extending 20km.](Bamako_Evolution.png){#fig-bamako-evolution}

![Built up extent of Bamako in 2000 (red) and 2025 (blue)](bamako_presence_superimposed_2020_2025.png){#fig-bamako-map}

### A typical classification problem

What you've got through is a typical classification problem. The goal of the classification (e.g.the "labels" you are interested in) and the input data might be different, but generally speaking, this is the blueprint. There are of course degrees of sophistication you could improve on. For example, in some tasks, the *dynamics* of the change are what is important. For example, if you are trying to map different types of trees, it might be useful to consider features in summer and winter, to easily separate evergreen and deciduous. Another refinement (specially if your data has a very fine spatial resolution) is to exploit the spatial context: in this practical, we have just taken pixels on their own, but pixels are often spatially correlated, so taking each pixel considering its neighbouring spatial context is a great idea. This is part of what makes so-called deep learning approaches so effective.

As EO measurements are quite indirect to what you're generally after, it pays to spend time removing additional sources of variance in the data, and pre-processing the data to emphasise the characteristics that are useful to your problem. Of course, properly phrasing your problem is also required (do you need to retrieve 15 landcover classes, or are you after one or two?). So simplifying the problem and selecting input features that are strongly linked to you phenomenon of study is generally a good idea. 

The indirect nature of the problem, augmented by the black box nature of most ML/classification algorithms is a risky prospect: plausible looking results are easy to get, but you need to build certainty on them. This is the role of the validation step: use an independent data set to test the classifier and assess its performance. Do not just consider one single metric, but report a broad suite of metrics, and use them to understand what is confusing the classifier. This exercise can guide you in refining the features you use. For example, in our study case, bare soils, vegetation and built up were confused to different degrees. Since we chose to use data from the dry season, we might be looking at vegetation that is very sparse, and mostly looks like soil. Were this an issue, adding perhaps a second wet season composite might help.

Collecting training data is fundamental, as it allows you to actually select samples of your requirements and match them up with the EO data. You should take a lot of care in selecting it, and you should err in the side of caution: if unsure, collect more training data. You can always use it to validate things if you don't use it for training. Ensure that your training set explores the true variability of the classes, and be aware that neighbouring pixels are strongly correlated, so prefer picking single points rather than large polygons. Stratify your sampling, and ensure you collect samples all over the region of interest (you don't want to biased to a small region). If you're doing multitemporal analyses like this one, you probably want to collect data at different periods, and covering different sensor configurations.

### The most important lesson: Watch out for the EO hubris!!

Perhaps the most important lesson when thinking about using EO with your projects is to start thinking: "Surely, someone must have had a go at this before me?". A large number of times, you will find that this is indeed the case, and that there is a large community of researchers that spend years finessing the best way of addressing the problem you're trying to solve by creating "products". 

Products are often freely available, well documented and validated, and if widely used, will have their inadequacies or other "glitches" exposed. For the case at hand, we could have used the **Global Human Settlement Layer** (described in some detail in [Pesaresi et al (2024)](https://doi.org/10.1080/17538947.2024.2390454)). This dataset extends EO data with detailed census data, and has been widely validated. Even if your final task is to use e.g., very high resolution optical data to map [slums](https://remote-sensing.org/a-decade-of-research-on-poverty-slums-and-informal-settlements-with-remote-sensing/), it is well worth considering using established products to at least cross-compare or to add additional information that simplifies your task.

