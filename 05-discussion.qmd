
## Tracking urban growth using EO. Discussion

### Counting pixels

Once you have your individual land cover masks, you can count pixels and plot the time series. The following script 
will classifiy each composite, and export them to GeoTIFFs so you can then do further analyses in e.g., QGIS or any other package

```javascript
// =======================
// GEE assets
// These are JGD's for Bamako, you might want to change that to your own!
// =======================
var classifier = ee.Classifier.load('users/xgomezdans/BamakoRFClassifier');

var training = ee.FeatureCollection('users/xgomezdans/BamakoTraining2018');
var roi = training.geometry().bounds();

// We need that the band names in the images and classifier match exactly
// This shouldn't be needed, but it's good to check
var bands = ["blue", "green", "red", "nir",
             "swir1", "swir2",
             "NDVI", "MNDWI", "NDBI", "UI", "IBI", "BRIGHT"];

var palette = [
  '#4575b4', // 0 water
  '#1a9850', // 1 veg
  '#d73027', // 2 bare
  '#fee08b'  // 3 builtup
];

/**** Client-side list of mosaics ****/
var mosaics = [
  {year: 2000, path: 'users/xgomezdans/Bamako_Mosaic_2000'},
  {year: 2005, path: 'users/xgomezdans/Bamako_Mosaic_2005'},
  {year: 2010, path: 'users/xgomezdans/Bamako_Mosaic_2010'},
  {year: 2015, path: 'users/xgomezdans/Bamako_Mosaic_2015'},
  {year: 2018, path: 'users/xgomezdans/Bamako_Mosaic_2018'},
  {year: 2020, path: 'users/xgomezdans/Bamako_Mosaic_2020'},
  {year: 2024, path: 'users/xgomezdans/Bamako_Mosaic_2024'}
];

// =======================
// Parameters
// =======================
var exportScale = 30;            // Landsat scale, 30m
var exportFolder = 'Bamako_RF';  // Google Drive folder name
var exportCrs = 'EPSG:4326';     // or set to your mosaic CRS if you prefer
var maxPixels = 1e13;

// Optional: map setup
Map.centerObject(roi, 10);
Map.addLayer(roi, {}, 'ROI', false);

// =======================
// Loop over mosaics (client-side)
// =======================
mosaics.forEach(function(m) {
  var year = m.year;
  var img = ee.Image(m.path);

  // Ensure band set + order matches what the classifier expects
  img = img.select(bands);

  // Classify!
  var classified = img.classify(classifier).rename('lc');

  // Clip for export tidiness
  // Since we only have 4 labels, we can use a Byte datatype to reduce
  // GeoTIFF storage
  classified = classified.clip(roi).toByte();

  // Quick visual check (optional)
  Map.addLayer(
    classified,
    {min: 0, max: 3, palette: palette},
    'Classified ' + year,
    false
  );

  // Export to Google Drive as GeoTIFF
  Export.image.toDrive({
    image: classified,
    description: 'Bamako_RF_' + year,
    folder: exportFolder,
    fileNamePrefix: 'Bamako_RF_' + year,
    region: roi,
    scale: exportScale,
//    crs: exportCrs, // Remove to keep the output in its original projection
    maxPixels: maxPixels
  });
});

print('Created export tasks for years:', mosaics.map(function(m){ return m.year; }));


```

The results from this, plotted using e.g. Python look like @fig-bamako-tm. The results show that for year 2005, there is a data issue: we see striping and notice that most of downtown Bamako is missing. This is probably due to persistent cloud and limited acquisitions in the compositing window. A similar pattern of striping is also clear in 2010. Since we build our classifier using data for 2018, when Landsat 8 was flying, we can also hypothesise that periods of data captured with the older Landsat 5 and 7 satellites might be degraded.

![Evolution of land cover around Bamako between 2000 and 2025 derived from Landsat data](Bamako_TM_tseries_2000_2025.png){#fig-bamako-tm width="90%"}

::: {callout.note}

Is it all lost? What could you do to improve on this situation? 
:::

### Watch out for the technological hubris!!

After all this, you now have a stack of images that allow you to look at the evolution of whatever city you chose to analyse. The process is fairly standard, but it does take effort. What's worse is that you will probably find that your results aren't quite what you expected them to be, as can be seen from the Bamako example!!!  It's notoriously hard to deal with long time series spanning decades and sensors in a simple workflow like the one we carried out here. Although we could take measures to improve screening and so on, this soon becomes a wild sheep chase

Perhaps the most important lesson when thinking about using EO with your projects is to start thinking: "Surely, someone must have had a go at this before me?". A large number of times, you will find that this is indeed the case, and that there is a large community of researchers that spend years finessing the best way of addressing the problem you're trying to solve by creating "products". 

Products are often freely available, well documented and validated, and if widely used, will have their inadequacies or other "glitches" exposed. For the case at hand, we could have used the **Global Human Settlement Layer** (described in some detail in [Pesaresi et al (2024)](https://doi.org/10.1080/17538947.2024.2390454)). This dataset extends EO data with detailed census data, and has been widely validated. Even if your final task is to use e.g., very high resolution optical data to map [slums](https://remote-sensing.org/a-decade-of-research-on-poverty-slums-and-informal-settlements-with-remote-sensing/), it is well worth considering using established products to at least cross-compare or to add additional information that simplifies your task.

### The Bamako case

In @fig-bamako-evolution, I show the evolution of Bamako in Mali from GHSL. The curve shows a fairly constant growth between 1975 and 2020, growing from around 60 square km to more than 140 square km, but the growth appears to flatten after 2020. Note that this could be an effect of timing of the product or other artefacts.

 We can also look at the spatial distribution of the growth (see @fig-bamako-map). Clearly, Bamako has continued growing along the Niger River, but also outside from it, and we can see how the build up area ends up making a continuum between the main Bamako city and the towns that existed around it in 2000. These results show similar trends to our own efforts, which have been put together with minimal data and doing a very simple workflow.


::: callout-note
If you are interested in the particular case of Bamako, you can read [(Keita et al. (2021))](https://doi.org/10.3390/urbansci5010004). This paper does something similar to what you have done here.

:::

![Evolution of the size of build up area for a radial region centred in Bamako (Mali) and extending 20km (GHSL).](bamako_built_area_trend_2000_2025.png){#fig-bamako-evolution}

![Built up extent of Bamako in 2000 (red) and 2025 (blue) (GHSL)](bamako_presence_superimposed_2000_red_2025_blue.png){#fig-bamako-map}

### A typical classification problem

What you've got through is a typical classification problem. The goal of the classification (e.g.the "labels" you are interested in) and the input data might be different, but generally speaking, this is the blueprint. There are of course degrees of sophistication you could improve on. For example, in some tasks, the *dynamics* of the change are what is important. For example, if you are trying to map different types of trees, it might be useful to consider features in summer and winter, to easily separate evergreen and deciduous. Another refinement (specially if your data has a very fine spatial resolution) is to exploit the spatial context: in this practical, we have just taken pixels on their own, but pixels are often spatially correlated, so taking each pixel considering its neighbouring spatial context is a great idea. This is part of what makes so-called deep learning approaches so effective.

As EO measurements are quite indirect to what you're generally after, it pays to spend time removing additional sources of variance in the data, and pre-processing the data to emphasise the characteristics that are useful to your problem. Of course, properly phrasing your problem is also required (do you need to retrieve 15 landcover classes, or are you after one or two?). So simplifying the problem and selecting input features that are strongly linked to you phenomenon of study is generally a good idea. 

The indirect nature of the problem, augmented by the black box nature of most ML/classification algorithms is a risky prospect: plausible looking results are easy to get, but you need to build certainty on them. This is the role of the validation step: use an independent data set to test the classifier and assess its performance. Do not just consider one single metric, but report a broad suite of metrics, and use them to understand what is confusing the classifier. This exercise can guide you in refining the features you use. For example, in our study case, bare soils, vegetation and built up were confused to different degrees. Since we chose to use data from the dry season, we might be looking at vegetation that is very sparse, and mostly looks like soil. Were this an issue, adding perhaps a second wet season composite might help.

Collecting training data is fundamental, as it allows you to actually select samples of your requirements and match them up with the EO data. You should take a lot of care in selecting it, and you should err in the side of caution: if unsure, collect more training data. You can always use it to validate things if you don't use it for training. Ensure that your training set explores the true variability of the classes, and be aware that neighbouring pixels are strongly correlated, so prefer picking single points rather than large polygons. Stratify your sampling, and ensure you collect samples all over the region of interest (you don't want to biased to a small region). If you're doing multitemporal analyses like this one, you probably want to collect data at different periods, and covering different sensor configurations.
